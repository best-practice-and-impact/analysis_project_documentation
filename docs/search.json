[
  {
    "objectID": "sample_assumptions_table.html",
    "href": "sample_assumptions_table.html",
    "title": "Example assumptions log",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.\nThis log contains a list of assumptions used in an analysis of data from UK universities. It also provides a score for each assumption.",
    "crumbs": [
      "Support and Feedback",
      "Example assumptions log"
    ]
  },
  {
    "objectID": "sample_assumptions_table.html#definitions",
    "href": "sample_assumptions_table.html#definitions",
    "title": "Example assumptions log",
    "section": "Definitions",
    "text": "Definitions\nAssumptions are scored as Red, Amber or Green (a RAG rating) depending on quality. In RAG, green denotes a favourable value, red unfavourable and amber neutral. The quality of an assumption measures both how certain and robust an assumption is and how appropriate it is for its intended use.\nFor example, we would usually consider a well documented assumption drawn from published evidence to be very robust, but if it needs to be transformed or adapted significantly to fit the analysis, the quality rating might need downgrading.\nYou would normally lower the quality rating of an assumption if you cannot get technical sign-off (for example because of lack of technical knowledge) or if the information on which it is based is incomplete or poor quality. You would also normally lower the quality if the confidence interval or uncertainty range is wide (i.e. you wouldn’t be surprised if the value was 50% different from what you measure because of uncertainty).\n\n\n\n\n\n\n\nRAG Rating\nAssumption quality\n\n\n\n\nGREEN\nBased on validated data; Methodology is robust; No or few transformations, or transformation methodology is fully verified and robust; Data is current and signed off by experts; Confidence intervals are narrow.\n\n\nAMBER\nThe methodology is robust but based on limited data; Data required significant transformation to fit the model; Confidence interval is quite wide; Data has not been reviewed recently.\n\n\nRED\nUnclear/unreliable data source or no data source provided; Based on limited data and methodology not robust; Data is not current; Confidence interval is wide or quality is unknown.\n\n\n\n\n\n\n\nAssumption ID\n\n\nDepends on Assumptions\n\n\nLocation in code, documentation or publication\n\n\nPlain English description of assumption\n\n\nBasis for assumption\n\n\nNumerical value of the assumption\n\n\nRange around the estimated value\n\n\nEstimated distribution\n\n\nLinks to supporting analysis\n\n\nDocumentation dependencies\n\n\nDate of last review/update\n\n\nExternally reviewed by\n\n\nDate of external review\n\n\nNext review/update due on\n\n\nQuality rating\n\n\nSensitivity score\n\n\nRisk score\n\n\n\n\n1\n\n\n2,3,4,5,6,7,8,9,10\n\n\nAssumption log\n\n\nWe assume that the dataset is representative of the population.\n\n\nTeam opinion\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nDescriptive statistics (link), comparison to existing data source/publication (link)\n\n\nFinal report: methods, caveats\n\n\n14/02/2024\n\n\nJohn Doe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nGREEN\n\n\nHigh\n\n\nHigh\n\n\n\n\n2\n\n\n3,4,5,6,8,9,10\n\n\nAssumption log\n\n\nWe assume that the data does not exclude any population groups based on their demographic and socio-economic characteristics.\n\n\nTeam opinion\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nDescriptive statistics (link), comparison to existing data source/publication (link)\n\n\nFinal report: methods, descriptive statistics, caveats\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nGREEN\n\n\nHigh\n\n\nHigh\n\n\n\n\n3\n\n\n\n\nCorrespondence with data provider\n\n\nWe assume that all UK universities report data to the Higher Education Statistics Agency (HESA).\n\n\nValidated from data provider, coverage check against university list\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nGREEN\n\n\nHigh\n\n\nMedium\n\n\n\n\n4\n\n\n3\n\n\nCorrespondence with data provider\n\n\nWe assume that our list of UK universities is correct, current and comprehensive.\n\n\nTeam opinion, reliable source (HESA list)\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nGREEN\n\n\nLow\n\n\nMedium\n\n\n\n\n5\n\n\n2,3,4\n\n\nAssumption log\n\n\nWe assume that all universities accurately report the number of students enrolled during the academic year.\n\n\nExpert opinion\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nFinal report: Caveats\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nAMBER\n\n\nHigh\n\n\nHigh\n\n\n\n\n6\n\n\n3,4\n\n\nAssumption log\n\n\nWe assume that all universities accurately report the number of students who dropped out during the academic year.\n\n\nExpert opinion\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nPublication on drop-out rates\n\n\nFinal report: Caveats\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n12/05/2024\n\n\nAMBER\n\n\nHigh\n\n\nHigh\n\n\n\n\n7\n\n\n3\n\n\nCorrespondence with data providers.\n\n\nWe assume that the academic year is consistently measured across UK universities.\n\n\nValidated from data provider\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nQuality assurance based on sampling universities from their websites\n\n\nQuality assurance log, final report: caveats\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nRED\n\n\nHigh\n\n\nHigh\n\n\n\n\n8\n\n\n9\n\n\nCorrespondence with data providers.\n\n\nWe assume that students who receive special education services are excluded from the calculation of dropout rates.\n\n\nValidated from data provider\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nSensitivity analysis comparing dropout rates with and without this population included.\n\n\nQuality assurance log, final report: methods, caveats\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nRED\n\n\nHigh\n\n\nHigh\n\n\n\n\n9\n\n\n2,3,4,10\n\n\nExploratory data analysis notebook (link)\n\n\nWe assume that there is complete information for all the variables in the analysis.\n\n\nRobustness testing\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nDescriptive statistics notebook link\n\n\nDesk instructions, final report: methods, summarising the sample\n\n\n14/02/2024\n\n\nJane Roe\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nAMBER\n\n\nHigh\n\n\nHigh\n\n\n\n\n10\n\n\n2,3,4,9\n\n\nCorrespondence with data provider\n\n\nWe assume that the data collection process has not changed at all over time.\n\n\nValidated from data provider (link)\n\n\nN/A\n\n\nN/A\n\n\nN/A\n\n\nMethods documents from prior runs of this work, supplier data specifications and quality reports\n\n\nData supply specification, data quality report, methods document\n\n\nNot yet assigned\n\n\nNo external review\n\n\n14/02/2024\n\n\n14/05/2024\n\n\nRED\n\n\nHigh\n\n\nHigh\n\n\n\n\n11\n\n\n2,3,4,5,6,7,8\n\n\nAssumption log\n\n\nWe assume that the correlation coefficient between the dropout rate and social grade of local authority of origin is 0.7\n\n\nStatistical analysis of past data\n\n\n0.7\n\n\n+-0.1\n\n\nNormal\n\n\nCorrelation analysis report m(link), comparison to domain knowledge (link)\n\n\nData analysis documentation\n\n\n05/12/2023\n\n\nJohn Doe\n\n\n05/12/2023\n\n\n01/05/2024\n\n\nGREEN\n\n\nMedium\n\n\nLow",
    "crumbs": [
      "Support and Feedback",
      "Example assumptions log"
    ]
  },
  {
    "objectID": "quality_questions.html",
    "href": "quality_questions.html",
    "title": "Quality Questions",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.\n\n\n\nTo get the most out of the template, we strongly recommend that teams identify who will take the key quality assurance roles of Commissioner, Approver and Assurer and name the analytical team at the start of the analytical cycle. This is crucial because together these roles help to make sure that the analysis you do is fit-for-purpose.\n\nI. Scoping\n\nQuality questions and why they matterThe questions and the Code of PracticeLinking the questions to AQuA Roles\n\n\n\n\n     \n     Quality Question\n     Why do I need to know the answer to this?\n\n \n  Q1\n  What question does the analysis try to answer?\n  A clear understanding of the analysis question is critical. It helps\n  your team to scope out requirements, understand the strengths and limitations of the analysis and make sure it is fit for purpose.\n  If the question is not clear, you risk designing and delivering analysis which does not meet user needs.\n \n \n  Q2\n  Why do you need to answer this analysis question?\n  Knowing why you need the analysis, what it is for and how it will be used will help you to understand the importance and impact of your work and how it supports decision making.It will also help you to make sure the analysis is fit for purpose and correctly answers the question.\n \n \n  Q3\n  Which organisational priorities does this analysis address?\n  Knowing how the work aligns with organisational priorities shows how it will fit with wider strategic objectives and why you should do the analysis now.It informs the level of assurance needed to confirm the work is fit for purpose.\n \n \n  Q4\n  If you use a model, is it business critical?\n  Identifying if the work is business critical determines the assurance needed to ensure it is fit for purpose.\n \n \n  Q5\n  Who needs the answer to the analysis question?\n  Knowing what your outputs will be used for can ensure they meet user needs. A good understanding of uses is essential for making sure that your analysis is fit for purpose.\n \n \n  Q6\n  Who do you need to consult to make sure you meet the right user\n  needs?\n  Analysis must be well understood by relevant users, or else\n  risks scope creep and misspecification.Identify relevant stakeholders and users, consult them before designing the analysis, and consider their views.Consulting the right stakeholders helps you and your users agree on how to answer the question and what the output should look like. This means you can check the users' understanding of the process and its quality, and that the final ouput meets user needs.\n \n \n  Q7\n  How will you know you have answered the analysis question correctly?\n  Being clear about the outputs required and acceptable uncertainty\n is essential for producing accurate and reliable outputs where users understand the work's limitations and uncertainty.It is also essential when designing verification and validation activities to check the robustness of results under a range of plausible assumptions about methods and data.\n \n \n  Q8\n  What is the estimated time and resource required to answer the analysis question (in months and FTE)?\n  Without a clear understanding of time and resources available,\n  you may overcommit. It is important to push back against unrealistic demands if there is not enough time to effectively quality assure the analysis.The users and commissioner should fully understand and accept increased risks to quality when time and resource pressures are unavoidable.\n \n \n  Q9\n  What is the impact if the analysis is not done now?\n  Understanding why the work needs to happen now will help you to\n  prioritise and use limited resources for the right activities.\n \n \n  Q10\n  What is the impact if the analysis is not done correctly?\n  Understanding the possible legal, financial or reputational consequences if the analysis is not carried out correctly helps you to design proportionate assurance activities.You should consider how these consequences line up with the risk appetite of your organisation when you design your mitigation.\n \n \n  Q11\n  Name the Commissioner, Approver and Assurer of this analysis?\n  Clear accountability makes sure that important decisions are \n  signed off by the right people. There should be a clear understanding of who is responsible for managing, producing and quality assuring the analysis in the team.\n \n \n  Q12\n  What tools and resources will you use in production? Are they the best for the job?\n  Before starting, identify all the skills and resources needed to produce the final output in a sustainable and reproducible way and quality assure it at every step.The platform used to host the analysis and the software to build and run the analysis should be appropriate and risks considered. For example, producing critical outputs in Excel does not comply with best practice and is unlikely to be robust or verifiable.\n \n \n  Q13\n  Do you have the right internal and external resources and\n  capability to deliver the analysis?\n  If the team lacks capability, resource, or time, this increases the risk that the analysis will not be fit for purpose or sufficiently assured.\n \n \n  Q14\n  What are the anticipated risks of the analysis?Have you\n  discussed these risks with customers and stakeholders?\n  You must identify potential risks and their impact well in advance to enable effective mitigation and quicker, confident decision-making.\n  It is important that users understand risks to ensure that their expectations and requirements are met. You should document how you have identified and are monitoring and mitigating risks.\n \n \n  Q15\n  Is there a contingency plan prepared if your mitigation plans fail?\n  You should account for risks that you can mitigate.  Include risks that have a high impact on the analysis but a low probability happening. Without well designed contingencies, we put quality at risk.\n \n \n  Q16\n  Do the data and analysis comply with ethical requirements?\n  Analysis must comply with ethics standards to ensure public confidence. You must consider the ethical implications of the analysis when you create the workflow and report your findings.\n \n \n  Q17\n  What relevant questions are outside the scope of the analysis?\n  Limiting the scope of analysis shapes the quality  of outputs and what can be done with them. By being clear about the limitations of the \n  analysis we can mitigate or accept them. Limitations must be documented so everybody using the analysis is aware of them.\n \n \n  Q18\n  How will you peer review and assure the analysis?\n  Internal audit and peer review are critical for monitoring and\n  assuring that the analysis is performed appropriately and meets the\n  required aims and objectives. The outcomes of peer review should be\n  documented and relevant actions and recommendations should be prioritised, addressed, and taken forward.\n \n \n  Q19\n  Will external experts be involved in development and scrutiny of\n  analysis?\n  You should commission external specialists to peer review or \n  audit the analysis in proportion to risks around use. They should be able to draw on expertise and experience across government and beyond to get feedback, exchange experience and suggest best practice to improve the analysis.\n  \n\n\n\n\n\n\n\n\nQuality Question\n\n\nWhich Code practice(s) are most relevant here?\n*Trustworthiness (T), Quality (Q), Value (V)\n\n\n\n\nQ1\n\n\nWhat question does the analysis try to answer?\n\n\nV8.2 Actively engage key users of your statistics, such as those in academia, business, civil society, the media and public bodies, to identify the most important questions the statistics need to answer. Report on the findings and your decisions in your annual statistical work programme\n\n\n\n\nQ2\n\n\nWhy do you need to answer this analysis question?\n\n\nV8.2 Actively engage key users of your statistics, such as those in academia, business, civil society, the media and public bodies, to identify the most important questions the statistics need to answer. Report on the findings and your decisions in your annual statistical work programme\n\n\n\n\nQ3\n\n\nWhich organisational priorities does this analysis address?\n\n\nT2.4 Seek the approval of the Chief Statistician/Head of Profession for Statistics for major revisions to statistics; new official statistics and official statistics in development; to cease the production of official statistics that are no longer viable or required; and when seeking a change to the accreditation of official statistics\n\n\n\n\nQ4\n\n\nIf you use a model, is it business critical?\n\n\nQ6.1 Produce statistics to a suitable level of quality that means they meet their intended uses and are not misleading\n\n\n\n\nQ5\n\n\nWho needs the answer to the analysis question?\n\n\nV8.2 Actively engage key users of your statistics, such as those in academia, business, civil society, the media and public bodies, to identify the most important questions the statistics need to answer. Report on the findings and your decisions in your annual statistical work programme\n\n\n\n\nQ6\n\n\nWho do you need to consult to make sure you meet the right user needs?\n\n\nV8.2 Actively engage key users of your statistics, such as those in academia, business, civil society, the media and public bodies, to identify the most important questions the statistics need to answer. Report on the findings and your decisions in your annual statistical work programmeV8.3 Gain views from a range of users to inform decisions on your work programme, including when statistics are started, stopped or changed, being clear on where and why user needs can and cannot be met, such as addressing information gaps. Involve users in the ongoing development and testing of statistics\n\n\n\n\nQ7\n\n\nHow will you know you have answered the analysis question correctly?\n\n\nQ6.9 Use a proportionate quality assurance approach across production and release processes. Validate statistics through comparison with other relevant statistics and data sources where possible\n\n\n\n\nQ8\n\n\nWhat is the estimated time and resource required to answer the analysis question (in months and FTE)?\n\n\nT2.7 Recruit suitably skilled staff and apply an appropriate competency framework. Have clear roles and responsibilities for these staffT2.8 Provide sufficient resources and time to enable staff to develop skills, knowledge and competencies, including training on applying the Code, secure data handling and quality managementT3.5 Release on a timely basis, meeting the needs of users as far as possible and as soon as the statistics are ready, under the guidance of the Chief Statistician/Head of Profession for Statistics\n\n\n\n\nQ9\n\n\nWhat is the impact if the analysis is not done now?\n\n\nT2.4 Seek the approval of the Chief Statistician/Head of Profession for Statistics for major revisions to statistics; new official statistics and official statistics in development; to cease the production of official statistics that are no longer viable or required; and when seeking a change to the accreditation of official statistics\n\n\n\n\nQ10\n\n\nWhat is the impact if the analysis is not done correctly?\n\n\nQ5.5 Periodically review the effectiveness of your processes and quality management approach and be open about findings and planned improvements\n\n\n\n\nQ11\n\n\nName the commissioner, senior responsible owner and analytical assurer of this analysis?\n\n\nT2.7 Recruit suitably skilled staff and apply an appropriate competency framework. Have clear roles and responsibilities for these staff\n\n\n\n\nQ12\n\n\nWhat tools and resources will you use in production? Are they the best for the job?\n\n\nT2.8 Provide sufficient resources and time to enable staff to develop skills, knowledge and competencies, including training on applying the Code, secure data handling and quality management\n\n\n\n\nQ13\n\n\nDo you have the right internal and external resources and capability to deliver the analysis?\n\n\nT2.8 Provide sufficient resources and time to enable staff to develop skills, knowledge and competencies, including training on applying the Code, secure data handling and quality management\n\n\n\n\nQ14\n\n\nWhat are the anticipated risks of the analysis? Have you discussed these risks with customers and stakeholders?\n\n\nQ6.9 Use a proportionate quality assurance approach across production and release processes. Validate statistics through comparison with other relevant statistics and data sources where possibleV8.3 Gain views from a range of users to inform decisions on your work programme, including when statistics are started, stopped or changed, being clear on where and why user needs can and cannot be met, such as addressing information gaps. Involve users in the ongoing development and testing of statistics\n\n\n\n\nQ15\n\n\nIs there a contingency plan prepared if your mitigation plans fail?\n\n\nQ5.1 Promote and apply appropriate quality standards, taking account of how quality can change\n\n\n\n\nQ16\n\n\nDo the data and analysis comply with ethical requirements?\n\n\nT1.2 Handle data and statistics with honesty and integrity, in ways that serve the public good\n\n\n\n\nQ17\n\n\nWhat relevant questions are outside the scope of the analysis?\n\n\nQ7.1 Prominently communicate the quality of the statistics and the strengths and limitations that impact their use, reflecting the needs of different types of usersQ7.3 Explain the nature of data sources and why they were selected, anticipating possible areas of misunderstanding or misuse. Prominently communicate limitations in the underlying data and explain their impact on the statistics\n\n\n\n\nQ18\n\n\nHow will you peer review and assure the analysis?\n\n\nQ5.4 Work collaboratively with data supply partners, other producers, topic experts and other partners to develop a common understanding of quality matters. Welcome and seek their input on ways to improve qualityQ6.9 Use a proportionate quality assurance approach across production and release processes. Validate statistics through comparison with other relevant statistics and data sources where possible\n\n\n\n\nQ19\n\n\nWill external experts be involved in development and scrutiny of analysis?\n\n\nQ6.8 Collaborate with experts, other analysts and statistics producers in the UK and internationally where appropriate and share best practice\n\n\n\n\n\n\n\n\n\n\nQuality Question\n\n\nWhich AQuA role(s) would normally answer this?\n\n\nWhy are these AQuA roles involved?\n\n\n\n\nQ1\n\n\nWhat question does the analysis try to answer?\n\n\nCommissioner, Analyst\n\n\nThe commissioner sets out the commission. They work with the analyst team to ensure that everyone has a common understanding of the problem.\n\n\n\n\nQ2\n\n\nWhy do we need to answer this analysis question?\n\n\nCommissioner, Analyst, Assurer\n\n\nThe analyst must document the purpose of the analysis and the levels of quality and certainty that are needed to meet user requirements. The commissioner and assurer make sure the analysis aligns with the stated purpose.\n\n\n\n\nQ3\n\n\nWhich organisational priorities does this analysis address?\n\n\nCommissioner\n\n\nThe commissioner makes sure that key aspects of the problem, scope and complexities, including programme constraints, are captured and clearly communicated. They also make sure there is proportionate governance in place to support the analysis and its role in the wider project or programme\n\n\n\n\nQ4\n\n\nIf you use a model, is it business critical?\n\n\nCommissioner, Approver\n\n\nBusiness critical models must be managed appropriately so that the right specialists are responsible for developing, using and assuring them.Decision-makers need sufficient assurance from an appropriate level in the organisation that the model is fit for purpose before using it to inform a decision. For business critical analysis and modelling, the commissioner should be satisfied with the seniority of the assurer.\n\n\n\n\nQ5\n\n\nWho needs the answer to the analysis question?\n\n\nCommissioner, Analyst, Assurer\n\n\nThe commissioner makes sure that the right stakeholders have been identified so that the scope and boundaries of the analysis can be appropriately explored. The analyst team and assurer should also contribute.\n\n\n\n\nQ6\n\n\nWho do you need to consult to make sure you meet the right user needs?\n\n\nAnalyst, Commissioner\n\n\nAnalysts should explore the analysis requirements and scope with all relevant stakeholders to make sure a wide range of perspectives are sought. The commissioner should be aware and briefed.\n\n\n\n\nQ7\n\n\nHow will you know you have answered the analysis question correctly?\n\n\nCommissioner, Analyst\n\n\nDuring the design and conduct of analysis, the commissioner should set out details like the level of precision, accuracy and uncertainty that are needed.\n\n\n\n\nQ8\n\n\nWhat is the estimated time and resource required to answer this analysis question (in months and FTE)?\n\n\nCommissioner, Approver, Analyst team\n\n\nDuring commissioning and scoping, the commissioner and analyst will need to make trade-offs between time, resources and quality. They should work together to agree and document the right balance across these constraints.\n\n\n\n\nQ9\n\n\nWhat is the impact if the analysis is not done now?\n\n\nCommissioner\n\n\nThe commissioner makes sure that there is sufficient time and resource for the required level of assurance to be delivered and that they understand the risks when time and resource pressures are unavoidable.\n\n\n\n\nQ10\n\n\nWhat is the impact if the analysis is not done correctly?\n\n\nCommissioner, Analyst\n\n\nThe commissioner makes sure the analyst team understands the context for the analysis question. This helps the analyst to understand and assess likely risks and determine the right analytical and quality assurance response.\n\n\n\n\nQ11\n\n\nName the Commissioner, Approver and Assurer of this analysis?\n\n\nCommissioner\n\n\nDuring scoping of the analysis, the commissioner makes sure there is proportionate governance in place to support the analysis and its role in the wider project or programme.\n\n\n\n\nQ12\n\n\nWhat tools and resources will you use in production? Are they the best for the job?\n\n\nCommissioner\n\n\nThe commissioner makes sure that there is enough time and resource for the required level of assurance to be delivered. They must be confident that they understand the risks when time and resource pressures are unavoidable.\n\n\n\n\nQ13\n\n\nDo you have the right internal and external resources and capability to deliver the analysis?\n\n\nCommissioner\n\n\nThe commissioner makes sure that there is enough time and resource for the required level of assurance to be delivered. They must be confident that they understand the risks when time and resource pressures are unavoidable.\n\n\n\n\nQ14\n\n\nWhat are the anticipated risks of the analysis?Have you discussed these risks with customers and stakeholders?\n\n\nAssurer, Commissioner, Analyst\n\n\nThe analystical assurer should challenge and test the understanding of the problem. The commissioner and analyst work with the assurer to make sure that all share a common understanding.\n\n\n\n\nQ15\n\n\nIs there a contingency plan prepared if your mitigation plans fail?\n\n\nCommissioner, Assurer\n\n\nThe commissioner makes sure that there is enough time and resource for the required level of assurance to be delivered. They must be confident that they understand the risks when time and resource pressures are unavoidable.If there is a need for urgent action, such as mitigation of unacceptable but uncertain risks, the commissioner may ask for further analysis. They might also commission extra evidence-gathering in parallel to inform the policy response when uncertainty is reduced. The assurer must advise the commissioner on whether sufficient analytical quality assurance has happened and inform them about any outstanding risks.\n\n\n\n\nQ16\n\n\nDo the data and analysis comply with ethical requirements?\n\n\nAnalyst, Commissioner, Assurer\n\n\nThe analyst should make sure that there is appropriate ethical approval for the analysis. The commissioner and assurer should be informed.\n\n\n\n\nQ17\n\n\nWhat relevant questions are outside the scope of the analysis?\n\n\nCommissioner, Analyst\n\n\nThe commissioner and the analyst work together at the scoping stage to get a clear understanding of analytical requirements. During scoping, the commissioner makes sure that the right aspects of the problem, scope and complexities, including programme constraints, are captured and clearly communicated.\n\n\n\n\nQ18\n\n\nHow will you peer review and assure the analysis?\n\n\nAssurer, Commissioner, Analyst\n\n\nThe assurer makes sure quality assurance plans for the analysis are appropriate for the decision it supports. All analysis requires some level of quality assurance. Analyst and commissioner should be involved.\n\n\n\n\nQ19\n\n\nWill external experts be involved in development and scrutiny of analysis?\n\n\nAssurer, Commissioner, Analyst\n\n\nThe assurer should challenge the proposed approach. Check that it delivers as intended and meets customer needs. It is good practice to engage subject matter experts in this review. Analyst and commissioner should be involved.\n\n\n\n\n\n\n\n\nII. Design\n\nQuality questions and why they matterThe questions and the Code of PracticeLinking the questions to AQuA Roles\n\n\n\n\n\n\n\nQuality Question\n\n\nWhy do I need to know the answer to this?\n\n\n\n\nQ20\n\n\nIs there a simple, plain English description of what the analysis is for and what it does?\n\n\nWriting a plain English description of what the analysis is for and how it works means that everybody in the team, including new starters, and others with no subject or technical expertise can understand the purpose of the analysis and what it does.\n\n\n\n\nQ21\n\n\nDoes the analysis have a logic flowchart which explains the end-to-end steps in the workflow?\n\n\nSetting out a clear summary of the analysis process in a diagram helps the team, users and customers to understand at a glance what the analysis does, where inputs come from, how they are processed and how it generates outputs.\n\n\n\n\nQ22\n\n\nWhen do you expect to start and finish each stage of analysis: data collection, processing, quality assurance, analysis and dissemination?\n\n\nClearly setting out the time you need to perform each stage of analysis helps you to evaluate if the time allocated to each stage is right and plan mitigation if plans look too ambitious.\n\n\n\n\nQ23\n\n\nDoes any part of the analysis rely on manual processing? Have you considered the cost and benefits of fully automating the process?\n\n\nManual processes are inefficient and more risky than well-designed automated ones. Analysis with manual steps like copying and pasting data between files, manually updating cells in tables, or moving data between software packages is harder to assure and carries extra quality risks.\n\n\n\n\nQ24\n\n\nWhat happens if team members, reviewers or users find a mistake in the analysis?Do you have a clear and efficient process for addressing issues and preventing them from happening again?\n\n\nMistakes happen in analysis. You should have a clear and efficient process for reporting, documenting and addressing errors. Being open and honest about problems and working together to solve them in a supportive way creates an atmosphere of openness in the team and is critical for upholding users’ trust in your output.Teams should take reasonable steps to understand and document how and why errors came about, and mitigate the risk of them happening again. Your mitigation approach should be consistent with your department’s revision policies.\n\n\n\nQ25\n\n\nHave you assessed uncertainty?\n\n\nConsider how uncertainty impacts on all stages of the analysis. Think about quantifying and measuring uncertainty as early as possible. Identify and review sources of uncertainty regularly.If you delay the assessment of uncertainty until late in the process, it is often difficult and costly to mitigate risks. In some cases, you may need to revise methods or alter commissioning decisions. If a potential source of uncertainty is overlooked, this can limit the usefulness and impact of the analysis.\n\n\n\n\n\n\n\n\n\n\n\nQuality Question\n\n\nWhich Code practice(s) are most relevant here?\n*Trustworthiness (T), Quality (Q), Value (V)\n\n\n\n\nQ20\n\n\nIs there a simple, plain English description of what the analysis is for and what it does?\n\n\nV9.4 Explain how the statistics add value and serve the public good, to demonstrate and help users and potential users understand how they could inform decision making\n\n\n\n\nQ21\n\n\nDoes the analysis have a logic flowchart which explains the end-to-end steps in the workflow?\n\n\nV10.2 Make sure statistics, data and related guidance are easily accessible. Provide other relevant information, such as metadata and coding where appropriate\n\n\n\n\nQ22\n\n\nWhen do you expect to start and finish each stage of analysis: data collection, processing, quality assurance, analysis and dissemination?\n\n\nQ6.1 Verify that the statistics are representative and of suitable quality and monitor relevant quality dimensions for both input data and the statistics, such as completeness and validity, accuracy and reliability, coherence and comparability, and timeliness. Quantify statistical error, including bias, and produce measures of confidence where possibleT3.5 Release on a timely basis, meeting the needs of users as far as possible and as soon as the statistics are ready, under the guidance of the Chief Statistician/Head of Profession for Statistics\n\n\n\n\nQ23\n\n\nDoes any part of the analysis rely on manual processing? Have you considered the cost and benefits of fully automating the process?\n\n\nQ5.2 Provide a supportive environment to enable staff to propose improvements in ways of working and raise quality concernsT2.8 Provide sufficient resources and time to enable staff to develop skills, knowledge and competencies, including training on applying the Code, secure data handling and quality management\n\n\n\n\nQ24\n\n\nWhat happens if team members, reviewers or users find a mistake in the analysis? Do you have a clear and efficient process for addressing issues and preventing them from happening again?\n\n\nQ5.2 Provide a supportive environment to enable staff to propose improvements in ways of working and raise quality concernsT3.9 Release revisions and corrections of errors transparently and as soon as possible in line with the organisation’s published policy, being clear about the nature and scale of change\n\n\n\n\nQ25\n\n\nHave you assessed uncertainty?\n\n\nQ7.2 Report on the key quality dimensions, such as accuracy and timeliness, and, where possible, give estimates of error and confidence for the statistics. Summarise how uncertainty in the estimates may impact use by using qualifying words, numbers or graphics\n\n\n\n\n\n\n\n\n\n\nQuality Question\n\n\nWhich AQuA role(s) would normally answer this?\n\n\nWhy are these AQuA roles involved?\n\n\n\n\nQ20\n\n\nIs there a simple, plain English description of what the analysis is for and what it does?\n\n\nAnalyst, Assurer\n\n\nThe analyst should produce sufficient design documentation. Best practice can include a description of the analysis, user requirements, design specification, functional specification, data dictionary, and test plan. The assurer should give feedback to make sure documentation is fit for purpose.\n\n\n\n\nQ21\n\n\nDoes the analysis have a logic flowchart which explains the end-to-end steps in the workflow?\n\n\nAnalyst, Assurer\n\n\nThe analyst should produce sufficient design documentation. Best practice can include a description of the analysis, user requirements, design specification, functional specification, data dictionary, and test plan. The assurer should give feedback to make sure documentation is fit for purpose.\n\n\n\n\nQ22\n\n\nWhen do you expect to start and finish each stage of analysis: data collection, processing, quality assurance, analysis and dissemination?\n\n\nCommissioner, Analyst\n\n\nThe analyst and commissioner should work together during scoping to set out and agree trade-offs between time, resources and quality and establish the optimal balance of these constraints.\n\n\n\n\nQ23\n\n\nDoes any part of the analysis rely on manual processing? Have you considered the cost and benefits of fully automating the process?\n\n\nCommissioner, Analyst\n\n\nThe analyst should use a risk-based approach to understand the areas of greatest potential error and focus assurance efforts on these areas. The analyst should brief the commissioner so they understand the impact of any reduction in the thoroughness of analytical quality assurance activities.\n\n\n\n\nQ24\n\n\nWhat happens if team members, reviewers or users find a mistake in the analysis?Do you have a clear and efficient process for addressing issues and preventing them from happening again?\n\n\nAnalyst, Assurer\n\n\nThe analyst should use a risk-based approach to highlight the areas of greatest potential error and focus assurance efforts on these areas.\n\n\n\n\nQ25\n\n\nHave you assessed uncertainty?\n\n\nCommissioner, Analyst\n\n\nCommissioners should expect and require information about uncertainty from analysts. They should challenge them when it is absent, inadequate or ambiguous.Commissioners may have identified sources of uncertainty as part of their wider considerations and should share them with the analyst. If the commissioner can explain in advance the impact on decision-making of different degrees of uncertainty, this can help the analyst to design and carry out the analysis at a proportionate level.\n\n\n\n\n\n\n\n\nIII. Analysis\n\nQuality questions and why they matterThe questions and the Code of PracticeLinking the questions to AQuA roles\n\n\n\n\n\n\n\nQuality Question\n\n\nWhy do I need to know the answer to this?\n\n\n\n\nQ26\n\n\nHow will the data in the analysis be processed before and during use?\n\n\nProcessing the data inputs will impact methods and outputs. A clear understanding of how these processes affect the workflow is essential for understanding quality.\n\n\n\n\nQ27\n\n\nIs the data appropriate given the methods selected?\n\n\nA comprehensive understanding of data inputs is a prerequisite for meeting user needs.\n\n\n\n\nQ28\n\n\nWhat are the strengths and limitations of the data you use?\n\n\nData requirements for analysis vary. Formats, coverage, time scales and granularity must all be appropriate for the research question.A comprehensive understanding of data inputs is a prerequisite for meeting user needs. Without understanding the strengths and weaknesses of the data, it is impossible to make meaningful improvements to the analysis or the inputs to manage these limitations.\n\n\n\n\nQ29\n\n\nIs there a robust relationship between your team and data providers?Do data providers understand how and why you use their data?\n\n\nA good relationship with data suppliers helps to make sure that their data meet your requirements. Lack of communication can mean you are not aware of quality risks or changes in collection or processing steps that can affect your results.You should communicate with your suppliers sufficiently to manage input quality. Data providers should have a good understanding of how and why you are using their data. This helps them to improve data quality and value and find and address gaps or issues that are relevant for your analysis.\n\n\n\n\nQ30\n\n\nDo you understand how data providers collect, process and quality assure the data you use?\n\n\nNever assume that datasets are of sufficient quality. Make sure that suppliers give you the metadata and other supporting information you need to assure the quality of the data. Validate the information provided by suppliers using your own checks and confirmation if appropriate.\n\n\n\n\nQ31\n\n\nIs there a formal agreement to set out data content, when and how you will get the data? If not, why not?\n\n\nA formal service level agreement with data providers makes sure that everybody understands what will be delivered, when and how. This is useful for setting out the division of responsibilities between data providers and your team for getting and sharing the data. It might specify formats, delivery, timescale, legal framework, accompanying metadata and quality checks.\n\n\n\n\nQ32\n\n\nDo you know what quality checks are carried out on the data before you receive them?\n\n\nData suppliers should be able to show that their data is sufficiently assured to meet your needs. You should be able to demonstrate that the data meet your needs and that reported quality matches what you observe in practice. Simply having a quality report is not enough.\n\n\n\n\nQ33\n\n\nHow will you work with your data provider when your data requirements change?\n\n\nReview your data requirements regularly to ensure they are still relevant and feasible. Changes to requirements should be communicated to data providers well in advance and agreed by all stakeholders. If there is a formal agreement, it may need to be revised as requirements change.\n\n\n\n\nQ34\n\n\nHow do you know if your data provider changes their systems or processes in a way that could impact the data you receive or the analysis you produce?\n\n\nData suppliers make changes to their definitions, methods and systems. This may not affect the quality of their data but can affect how you process the data and what you can infer from it. Tailor communication with data suppliers so it is sufficiently frequent, effective and ongoing to get timely information about changes.\n\n\n\n\nQ35\n\n\nHow did you choose the methods for the analysis? How do you know the methods you use are appropriate?\n\n\nYou should be able to explain why you chose your methods. For each method, document the underlying assumptions, why the method is suitable for answering the analysis question, why it is applicable to the type and distribution of data you are using, and how these decisions were signed off.\n\n\n\n\nQ36\n\n\nHave reasonable alternative methods been explored and rejected for good reasons?\n\n\nThere is often more than one way to answer a question with data. When you have made choices about methods and approaches, explain how and why you considered and rejected other options. Unless there is evidence underpinning your choice, users cannot be sure that you have chosen the most suitable methods.\n\n\n\n\nQ37\n\n\nHow do you know that your analysis is working correctly?\n\n\nYou need to be sure that your analysis produces the outputs you think it should and the processes run as expected. If you cannot demonstrate that scripts and processes work correctly, you cannot confirm the quality of the results.\n\n\n\n\nQ38\n\n\nCan you describe the assumptions of your analysis, when they were made and who made them and signed them off?\n\n\nYou must understand the assumptions your analysis makes. Assumptions set out how the analysis simplifies the world and mitigates uncertainty. If assumptions are inadequately set out or absent, important characteristics of the analysis and its inputs will be unclear, greatly increasing risk.Without a comprehensive log of assumptions made by the analysis, an audit trail signed off by assumption owners, a version control log reflecting when assumptions were last updated, and evidence showing internal and external validation of assumptions, uncertainties may go unacknowledged and could drastically impact outputs.\n\n\n\n\nQ39\n\n\nHow are assumptions validated and assured before you apply them?\n\n\nA clear understanding of how assumptions have been externally and internally validated and signed off gives us confidence that they are reasonable.\n\n\n\n\nQ40\n\n\nHow do you measure and report uncertainty in your analysis?\n\n\nAll analysis contains uncertainty. Quantifying and reporting uncertainty means we can inform users how precise reported values are and how much confidence they can have in the analysis. It will also help you to determine where the analysis can be improved.There are many ways to quantify uncertainty in input data, assumptions, processes and outputs. Choose appropriate ones for your situation. For instance, uncertainties can be understood and quantified by comparing against similar or historical data, Monte Carlo simulation, break-even analysis or using expert judgement.\n\n\n\n\nQ41\n\n\nHave you considered the implications of relevant, unquantified uncertainties?\n\n\nA good understanding of the uncertainties in the analysis workflow is critical to ensure the analysis and its outputs are fit for purpose.\n\n\n\n\nQ42\n\n\nCan you explain the impact of your analysis on downstream processes? Are there any risks around these dependencies?\n\n\nUnderstanding how your analysis might be used would help ensure that the right quality and assurance levels are in place. It would help you assess the risks around the use of analysis and if there are other stakeholders or users you need to consult.\n\n\n\n\nQ43\n\n\nIs all or part of the analysis reliant on a single person?\n\n\nSingle points of failure carry significant business risk. If only one person understands how to carry out all or part of the analysis or maintain the code then the process is extremely vulnerable.\n\n\n\n\nQ44\n\n\nIs it clear why important decisions about the analysis were made, who made them and when?\n\n\nAll analysis involves decisions. A comprehensive record of the decisions made in specifying and conducting the analysis ensures a full audit trail of why decisions were made, who made them and signed them off.\n\n\n\n\nQ45\n\n\nIf changes need to be made to code or datasets, is it easy to track who made the changes and when and why they were made?\n\n\nGood version control ensures a full understanding of when, why, and how changes were made to your analysis process. If it is hard to track changes, it will be hard to retrace steps if there is a problem and means you do not fully understand the process.\n\n\n\n\nQ46\n\n\nWould another analyst be able to reproduce your analysis output or continue the work without talking to you first?\n\n\nYour analysis must be well documented and repeatable so that somebody new can understand it, use it, and produce the same output with the same inputs. Poor documentation can lead to errors.\n\n\n\n\nQ47\n\n\nDo you use internal peer review to check scripts and code, documentation, implementation of methods, processes and outputs?\n\n\nYou should independently review and validate the logical integrity of you analysis as well as the structure and functionality of the code against the research question.A record of validation and verification activities undertaken, outstanding tasks and remedial actions helps to confirm that the correct analysis has been performed for the required purpose and the chosen approach minimises risk.\n\n\n\n\nQ48\n\n\nIs your code and analysis ever peer reviewed by someone outside your team or organisation?\n\n\nExternal peer review is one of the best ways to ensure that the analysis and code are well made and fit for purpose. Without it, teams can reinforce their own biases and may not notice there is anything wrong.\n\n\n\n\nQ49\n\n\nWhat is your assessment of the quality of your analytical outputs?\n\n\nUnderstanding and reporting on the quality of your analysis is critical to ensure fitness for purpose and maintain trust and reliability. This ensures that analysis can appropriately inform decision-making. Quality assessments are key information to share with users and a requirement of the Code of Practice for Statistics.\n\n\n\n\nQ50\n\n\nHow do you assure yourselves that analysis you do is correct?\n\n\nIf you check that results fit with your expectations and you can explain discrepancies, this makes it easier to mitigate risk.There are many ways to check if analysis is carried out correctly. For example, sensitivity analysis can help you understand which inputs have the greatest effect on the outputs.You can also compare figures from the analysis with similar data from other sources or from historical series.\n\n\n\n\nQ51\n\n\nDo the outputs of your analysis align with similar findings from elsewhere? If not, can you explain why?\n\n\nIf you can, check that your outputs align with findings from previous runs of the analysis, alternate data sources, and comparable studies. This gives you confidence that the analysis works as expected. You should be able to explain any inconsistencies that you see.\n\n\n\n\nQ52\n\n\nIf you find outliers or unusual trends in the data, what steps do you take to investigate them?\n\n\nIt is crucial to check unusual trends and values in the data and understand why they are there. Not all outliers are the same. Some have a strong influence, some not at all. Some are valid and important data values. Others might be errors.Investigate outliers and unusual patterns thoroughly and take reasonable steps to check their impact on your final output. If you choose to exclude unusual values, you should explain why this is acceptable.\n\n\n\n\n\n\n\n\n\n\nQuality Question\n\n\nWhich Code practice(s) are most relevant here?\n*Trustworthiness (T), Quality (Q), Value (V)\n\n\n\n\nQ26\n\n\nHow will the data in the analysis be processed before and during use?\n\n\nQ7.4 Be clear about the methods used. Explain quality issues related to the methods, systems and processes, including the extent to which the statistics are representative and comparable across the UK and internationally. Describe potential bias and steps taken to address it\n\n\n\n\nQ27\n\n\nIs the data appropriate given the methods selected?\n\n\nQ7.3 Explain the nature of data sources and why they were selected, anticipating possible areas of misunderstanding or misuse. Prominently communicate limitations in the underlying data and explain their impact on the statistics\n\n\n\n\nQ28\n\n\nWhat are the strengths and limitations of the data you use?\n\n\nQ6.2 Use the most suitable data for what needs to be measured. Monitor for changes in the data sources and potential bias in the data. Explain any issues and their implications for use of the data in producing statisticsQ7.3 Explain the nature of data sources and why they were selected, anticipating possible areas of misunderstanding or misuse. Prominently communicate limitations in the underlying data and explain their impact on the statistics\n\n\n\n\nQ29\n\n\nIs there a robust relationship between your team and data providers? Do data providers understand how and why you use their data?\n\n\nQ6.4 Maintain constructive relationships with those involved in the data provision, statistics preparation and quality assurance processes. Be clear about your data supply and quality requirements and understand how these will be met. Where possible, provide feedback to data suppliers on your use of their data\n\n\n\n\nQ30\n\n\nDo you understand how data providers collect, process and quality assure the data you use?\n\n\nQ5.4 Work collaboratively with data supply partners, other producers, topic experts and other partners to develop a common understanding of quality matters. Welcome and seek their input on ways to improve qualityQ6.4 Maintain constructive relationships with those involved in the data provision, statistics preparation and quality assurance processes. Be clear about your data supply and quality requirements and understand how these will be met. Where possible, provide feedback to data suppliers on your use of their data\n\n\n\n\nQ31\n\n\nIs there a formal agreement to set out data content, when and how you will get the data? If not, why not?\n\n\nQ6.4 Maintain constructive relationships with those involved in the data provision, statistics preparation and quality assurance processes. Be clear about your data supply and quality requirements and understand how these will be met. Where possible, provide feedback to data suppliers on your use of their data\n\n\n\n\nQ32\n\n\nDo you know what quality checks are carried out on the data before you receive them?\n\n\nQ6.4 Maintain constructive relationships with those involved in the data provision, statistics preparation and quality assurance processes. Be clear about your data supply and quality requirements and understand how these will be met. Where possible, provide feedback to data suppliers on your use of their data\n\n\n\n\nQ33\n\n\nHow will you work with your data provider when your data requirements change?\n\n\nQ6.4 Maintain constructive relationships with those involved in the data provision, statistics preparation and quality assurance processes. Be clear about your data supply and quality requirements and understand how these will be met. Where possible, provide feedback to data suppliers on your use of their data\n\n\n\n\nQ34\n\n\nHow do you know if your data provider makes a change to their systems or processes which could impact the data you receive or the analysis you produce?\n\n\nQ5.4 Work collaboratively with data supply partners, other producers, topic experts and other partners to develop a common understanding of quality matters. Welcome and seek their input on ways to improve qualityQ6.4 Maintain constructive relationships with those involved in the data provision, statistics preparation and quality assurance processes. Be clear about your data supply and quality requirements and understand how these will be met. Where possible, provide feedback to data suppliers on your use of their data\n\n\n\n\nQ35\n\n\nHow did you choose the methods for the analysis? How do you know the methods you use are appropriate?\n\n\nQ6.7 Base methods on national or international good practice, scientific principles or professional consensus. Identify potential bias and address limitations. Use recognised standards, classifications and definitions. Explain reasons for deviations from these standards and any related implications for use\n\n\n\n\nQ36\n\n\nHave reasonable alternative methods been explored and rejected for good reasons?\n\n\nQ6.7 Base methods on national or international good practice, scientific principles or professional consensus. Identify potential bias and address limitations. Use recognised standards, classifications and definitions. Explain reasons for deviations from these standards and any related implications for use\n\n\n\n\nQ37\n\n\nHow do you know that your analysis is working correctly?\n\n\nQ6.1 Verify that the statistics are representative and of suitable quality and monitor relevant quality dimensions for both input data and the statistics, such as completeness and validity, accuracy and reliability, coherence and comparability, and timeliness. Quantify statistical error, including bias, and produce measures of confidence where possible\n\n\n\n\nQ38\n\n\nCan you describe the assumptions of your analysis, when they were made and who made them and signed them off?\n\n\nQ7.4 Be clear about the methods used. Explain quality issues related to the methods, systems and processes, including the extent to which the statistics are representative and comparable across the UK and internationally. Describe potential bias and steps taken to address it\n\n\n\n\nQ39\n\n\nHow are assumptions validated and assured before you apply them?\n\n\nQ6.1 Regularly review strengths and limitations in the data and statistics, including the continued suitability of data sources and methods. Be open about your decisions and reasons for changeQ7.3 Explain the nature of data sources and why they were selected, anticipating possible areas of misunderstanding or misuse. Prominently communicate limitations in the underlying data and explain their impact on the statisticsQ7.4 Be clear about the methods used. Explain quality issues related to the methods, systems and processes, including the extent to which the statistics are representative and comparable across the UK and internationally. Describe potential bias and steps taken to address it\n\n\n\n\nQ40\n\n\nHow do you measure and report uncertainty in your analysis?\n\n\nQ6.1 Verify that the statistics are representative and of suitable quality and monitor relevant quality dimensions for both input data and the statistics, such as completeness and validity, accuracy and reliability, coherence and comparability, and timeliness. Quantify statistical error, including bias, and produce measures of confidence where possible\n\n\n\n\nQ41\n\n\nHave you considered the implications of relevant, unquantified uncertainties?\n\n\nQ7.2 Report on the key quality dimensions, such as accuracy and timeliness, and, where possible, give estimates of error and confidence for the statistics. Summarise how uncertainty in the estimates may impact use by using qualifying words, numbers or graphics\n\n\n\n\nQ42\n\n\nCan you explain the impact of your analysis on downstream processes? Are there risks around these dependencies?\n\n\nQ7.1 Prominently communicate the quality of the statistics and the strengths and limitations that impact their use, reflecting the needs of different types of users\n\n\n\n\nQ43\n\n\nIs all or part of the analysis reliant on a single person?\n\n\nT2.7 Recruit suitably skilled staff and apply an appropriate competency framework. Have clear roles and responsibilities for these staffT2.8 Provide sufficient resources and time to enable staff to develop skills, knowledge and competencies, including training on applying the Code, secure data handling and quality management\n\n\n\n\nQ44\n\n\nIs it clear why important decisions about the analysis were made, who made them and when?\n\n\nQ6.7 Base methods on national or international good practice, scientific principles or professional consensus. Identify potential bias and address limitations. Use recognised standards, classifications and definitions. Explain reasons for deviations from these standards and any related implications for use\n\n\n\n\nQ45\n\n\nIf changes need to be made to code or datasets, is it easy to track who made the changes and when and why they were made?\n\n\nV10.5 Support the reuse of data and statistics, preventing barriers to use where possible. Ensure statistics are reproducible. Support data and statistics to be shared, accessed and linked, using common data standards with associated metadata\n\n\n\n\nQ46\n\n\nWould another analyst be able to reproduce your analysis output or continue the work (without talking to you first)?\n\n\nV10.5 Support the reuse of data and statistics, preventing barriers to use where possible. Ensure statistics are reproducible. Support data and statistics to be shared, accessed and linked, using common data standards with associated metadata\n\n\n\n\nQ47\n\n\nDo you use internal peer review to check scripts and code, documentation, implementation of methods, processes and outputs?\n\n\nQ5.5 Periodically review the effectiveness of your processes and quality management approach and be open about findings and planned improvementsT4.6 Hold regular reviews of the data management arrangements used and share best practice across the organisation to ensure data protection procedures remain effective. Keep pace with changing circumstances such as technological advances\n\n\n\n\nQ48\n\n\nIs your code and analysis ever peer reviewed by someone outside your team or organisation?\n\n\nQ5.5 Periodically review the effectiveness of your processes and quality management approach and be open about findings and planned improvementsT4.6 Hold regular reviews of the data management arrangements used and share best practice across the organisation to ensure data protection procedures remain effective. Keep pace with changing circumstances such as technological advances\n\n\n\n\nQ49\n\n\nWhat is your assessment of the quality of your analytical outputs?\n\n\nQ6.1 Verify that the statistics are representative and of suitable quality and monitor relevant quality dimensions for both input data and the statistics, such as completeness and validity, accuracy and reliability, coherence and comparability, and timeliness. Quantify statistical error, including bias, and produce measures of confidence where possibleQ6.9 Use a proportionate quality assurance approach across production and release processes. Validate statistics through comparison with other relevant statistics and data sources where possible\n\n\n\n\nQ50\n\n\nHow do you assure yourself that the analysis you do is correct?\n\n\nQ6.1 Regularly review strengths and limitations in the data and statistics, including the continued suitability of data sources and methods. Be open about your decisions and reasons for changeQ6.1 Verify that the statistics are representative and of suitable quality and monitor relevant quality dimensions for both input data and the statistics, such as completeness and validity, accuracy and reliability, coherence and comparability, and timeliness. Quantify statistical error, including bias, and produce measures of confidence where possible\n\n\n\n\nQ51\n\n\nDo the outputs of your analysis align with similar findings from elsewhere? If not can you explain why?\n\n\nQ6.9 Use a proportionate quality assurance approach across production and release processes. Validate statistics through comparison with other relevant statistics and data sources where possible\n\n\n\n\nQ52\n\n\nIf you find outliers or unusual trends in the data, what steps do you take to investigate them?\n\n\nQ5.3 Promote the sharing of good practice and examples of effective quality management. Learn from both mistakes and good practice and conduct timely reviews of quality concernsQ6.1 Verify that the statistics are representative and of suitable quality and monitor relevant quality dimensions for both input data and the statistics, such as completeness and validity, accuracy and reliability, coherence and comparability, and timeliness. Quantify statistical error, including bias, and produce measures of confidence where possible\n\n\n\n\n\n\n\n\n\n\nQuality Question\n\n\nWhich AQuA role(s) would normally answer this?\n\n\nWhy are these AQuA roles involved?\n\n\n\n\nQ26\n\n\nHow will the data used in the analysis be processed before and during use?\n\n\nAnalyst, Assurer\n\n\nThe analyst should collect and manage the data. They must understand data accuracy and uncertainties and capture, manage and understand assumptions. Assurer should check that data processing is sufficient to ensure fitness for purpose.\n\n\n\n\nQ27\n\n\nIs the data appropriate given the methods selected?\n\n\nAnalyst, Assurer, Commissioner\n\n\nThe analyst should understand data accuracy and uncertainties and capture, manage and understand assumptions made. The analyst should engage appropriate subject matter experts at the appropriate time. The commissioner may be a subject matter expert. The assurer should check that there is sufficient assurance around the choice of data.\n\n\n\n\nQ28\n\n\nWhat are the strengths and limitations of the data you use?\n\n\nAnalyst, Assurer\n\n\nIf applicable, analyst should undertake parametric analysis to understand the consequences of missing or uncertain data and assumptions. Assurer should make sure there is sufficient consideration of strengths and limitations of data.\n\n\n\n\nQ29\n\n\nIs there a robust relationship between your team and data providers?Do data providers understand how and why you use their data?Do you understand how data providers collect, process and quality assure the data you use?\n\n\nAnalyst, Assurer\n\n\nThe assurer should expect to see evidence that there has been sufficient dialogue between analysts and the providers of data and other evidence sources.\n\n\n\n\nQ30\n\n\nDo you understand how data providers collect, process and quality assure the data you use?\n\n\nAnalyst, Assurer\n\n\nThe analyst should ensure data formats, units, and context are properly understood and handled. They should design and implement quality checks to validate data inputs as required. Assurer should verify that the right assurance is in place.\n\n\n\n\nQ31\n\n\nIs there a formal agreement to set out data content, when and how you will get the data? If not, why not?\n\n\nCommissioner, Analyst, Assurer\n\n\nThe commissioner may need to provide the analyst with agreement to use specific data. The analyst should ensure data formats, units, and context are properly understood and handled. Assurer should verify that assurance is in place.\n\n\n\n\nQ32\n\n\nDo you know what quality checks are carried out on the data before you receive them?\n\n\nAnalyst\n\n\nThe analyst should understand data accuracy and uncertainties and capture, manage and understand implicit assumptions made. The assurer should assess whether assurance is sufficient.\n\n\n\n\nQ33\n\n\nHow will you work with your data providers when your data requirements change?\n\n\nCommissioner, Analyst, Assurer\n\n\nDuring the design and conduct of analysis, the commissioner may need to provide the analyst with information, agreement to use resources or confirmation of assumptions or approach. The analyst should understand data accuracy and uncertainties and capture, manage and understand implicit assumptions made. The assurer checks that assurance and mitigation are sufficient.\n\n\n\n\nQ34\n\n\nHow do you know if your data provider changes their systems or processes in a way that could impact the data you receive or the analysis you produce?\n\n\nCommissioner, Analyst, Assurer\n\n\nDuring the design and conduct of analysis, the commissioner provides the analyst with the information they need for the analysis to proceed. This could include agreement to use datasets, setting out of key assumptions and signing off assumptions developed during the project. Analyst should understand data accuracy and uncertainties and capture, manage and understand assumptions made. The assurer checks that assurance and mitigation are sufficient.\n\n\n\n\nQ35\n\n\nHow did you choose the methods for the analysis? How do you know the methods you use are appropriate?\n\n\nAnalyst, Assurer\n\n\nDuring the design phase, the analyst will convert the commission into an analytical plan and will consider inputs, analytical methods and processes, and expected outputs. The assurer should check that the proposed design meets the commissioner’s requirements and is sufficiently assured.\n\n\n\n\nQ36\n\n\nHave reasonable alternative methods been explored and rejected for good reasons?\n\n\nAnalyst, Assurer\n\n\nThe analyst should review the analysis as a whole and consider carefully whether there are other, better ways in which it could be done. The assurer should check that the investigation of methods was sufficiently thorough and proportionate.\n\n\n\n\nQ37\n\n\nHow do you know that your analysis is working correctly?\n\n\nAnalyst, Assurer\n\n\nThe analyst should validate that the analysis as set up to answer the specification of the commissioner. The assurer checks that assurance and mitigation are sufficient so the analysis is fit for purpose.\n\n\n\n\nQ38\n\n\nCan you describe the assumptions of your analysis, when they were made and who made them and signed them off?\n\n\nAnalyst, Assurer, Commissioner\n\n\nThe analyst should capture, manage and understand explicit and implicit assumptions made. The assurer should assess whether these are sufficient. The commissioner should be made aware of key assumptions and confirm that they are happy that the assumptions are applied.\n\n\n\n\nQ39\n\n\nHow are assumptions validated and assured before you apply them?\n\n\nAnalyst, Assurer\n\n\nIf applicable, analyst should undertake parametric analysis to understand the consequences of missing or uncertain assumptions. Assurer should check that validation and assurance of assumptions is sufficient.\n\n\n\n\nQ40\n\n\nHow do you measure and report uncertainty in your analysis?\n\n\nAnalyst, Commissioner, Assurer\n\n\nAnalyst should determine and communicate the uncertainty associated with outputs so that the commissioner can make informed decisions. The range of possible outcomes and their relative likelihoods should be described. The assurer checks that measuring and reporting of uncertainty is sufficient to meet the needs of the commissioner.\n\n\n\n\nQ41\n\n\nHave you considered the implications of relevant, unquantified uncertainties?\n\n\nAnalyst, Commissioner\n\n\nIf uncertainties are too complex for analysts to quantify, even approximately, the analysts should say so in order that the commissioner can take this into account.\n\n\n\n\nQ42\n\n\nCan you explain the impact of your analysis on downstream processes? Are there risks around these dependencies?\n\n\nAnalyst, Assurer\n\n\nAnalyst should make sure that the implications of data dependencies or relationships to other analysis and methods are understood. Assurer should check that dependencies have been properly considered.\n\n\n\n\nQ43\n\n\nIs all or part of the analysis reliant on a single person?\n\n\nAssurer, Analyst, Commissioner\n\n\nAnalysis should be peer reviewed at an appropriate and proportionate level by a competent person. Comissioner, analyst and assurer should all be involved in each stage of the analytical cycle.\n\n\n\n\nQ44\n\n\nIs it clear why important decisions about the analysis were made, who made them and when?\n\n\nAssurer, Analyst\n\n\nThe assurer should make sure that a suitable audit trail is in place that clarifies the level of validation, scope, and risks associated with the analysis. Best practice includes the production of validation log books. Analyst should build this audit trail.\n\n\n\n\nQ45\n\n\nIf changes need to be made to code or datasets, is it easy to track who made the changes and when and why they were made?\n\n\nAssurer, analyst\n\n\nTo make analytical audit easy, you should set up a version control system for the analysis as a whole and for code, supporting data and assumptions. Best practice includes the production of validation log books. Analyst should build this audit trail.The assurer should ensure that the audit trail clarifies the level of validation, scope, and risks associated with the analysis.\n\n\n\n\nQ46\n\n\nWould another analyst be able to reproduce your analysis output or continue the work without talking to you first?\n\n\nAnalyst, Assurer\n\n\nGood quality analysis is reproducible. Analyst should check that the analytical process reflects the principles of RIGOUR (Repeatable, Independent, Grounded in reality, Objective, Uncertainty-managed, Robust)\n\n\n\n\nQ47\n\n\nDo you use internal peer review to check scripts and code, documentation, implementation of methods, processes and outputs?\n\n\nAnalyst, Assurer\n\n\nThe analyst should provide proportionate documentation that explains the verification and validation activities that the analysis is subjected to. Analysts must perform appropriate test to check the analysis. They should commission other verification and validation as required. Assurer should confirm that planned validation and verification are sufficient.\n\n\n\n\nQ48\n\n\nIs your code and analysis ever peer reviewed by someone outside your team or organisation?\n\n\nAnalyst, Assurer\n\n\nAnalysts should work with the commissioner to set out the analysis question so that appropriate analysis is done. Some analysis may require external specialists, so analysts may have responsibilities as part of the procurement process. Analysts, including 3rd parties providing analysis, should provide proportionate documentatiob describing the verification and validation activities undertaken and associated conclusions. The assurer advises the commissioner on whether appropriate analytical quality assurance has taken place.\n\n\n\n\nQ49\n\n\nWhat is your assessment of the quality of your analytical outputs?\n\n\nCommissioner, Assurer\n\n\nAs part of the delivery phase, the commissioner should ensure there is an assessment of the level of analytical quality assurance of the analysis, noting where there have been trade-offs between time, resources and quality. The assurer advises the commissioner on whether appropriate analytical quality assurance has taken place.\n\n\n\n\nQ50\n\n\nHow do you assure yourself that the analysis you do is correct?\n\n\nCommissioner, Analyst, Assurer\n\n\nThe analyst must build in checks and processes to ensure that the analysis is correct. During the delivery phase, the commissioner should give feedback to assist in the correct interpretation of results and determine if the analysis has addressed the commission. The analyst should work with the assurer while doing the analysis so that they can comment on whether the analysis meets the needs of the commission to ensure best use of the results\n\n\n\n\nQ51\n\n\nDo the outputs of your analysis align with similar findings from elsewhere? If not, can you explain why?\n\n\nCommissioner, Analyst\n\n\nWhen interpreting the results of a piece of analysis, the commissioner provides constructive challenge. They work with the analyst to explore whether further analysis is needed.\n\n\n\n\nQ52\n\n\nIf you find outliers or unusual trends in the data, what steps do you take to investigate them?\n\n\nAnalyst, Assurer\n\n\nIf applicable, analyst should undertake parametric analysis to understand the consequences of missing or uncertain data and assumptions. The analysis plan should include treatment of unusual values and outliers. Assurer should be involved.\n\n\n\n\n\n\n\n\nIV. Delivery\n\nQuality questions and why they matterThe questions and the Code of PracticeLinking the questions to AQuA roles\n\n\n\n\n\n\n\nQuality Question\n\n\nWhy do I need to know the answer to this?\n\n\n\n\nQ53\n\n\nCan you give a clear account of what can and cannot be inferred from the analysis?\n\n\nOften the aim of final output is to inform decison-making. Output might include predictions, involving lots of underlying assumptions. It is critical that you support your users to make appropriate use of outputs and understand what can and cannot be inferred. Without this, users may misinterpret findings, make in appropriate comparisons, use the analysis for unsuitable purposes and arrive at the wrong conclusions. For example, a non-expert user may wrongly interpret correlation as causation or use incomplete or disconnected data to make forecasts.\n\n\n\n\nQ54\n\n\nHave you assessed the limitations of the data and analysis and set out how they affect the quality and use of the outputs?\n\n\nYou should describe why limitations related to data and methods exist, why they cannot be overcome using the chosen approach and their impact on the quality and interpretation of the output. Analysis is of very little value if limitations aren’t properly documented and explained.\n\n\n\n\nQ55\n\n\nHave you sense checked outputs with user groups and stakeholders?\n\n\nYou should work with users, experts, and other relevant stakeholders to verify the credibility of outputs and sense check that they are useful.\n\n\n\n\nQ56\n\n\nIs uncertainty about data quality, assumptions and methodology clearly communicated to users?\n\n\nOutputs are never 100% accurate. Users need to understand how uncertainties related to data, assumptions and methodology feed into and through the analysis workflow and what this means for the use of the outputs. Results must clearly explain how uncertainty affects the findings from the analysis, or we risk misinterpretations and conclusions being overly reliant on imprecise results.\n\n\n\n\nQ57\n\n\nAre the implications of unquantified uncertainties communicated to users?\n\n\nYou must support your users to understand relevant uncertainties which are not captured in the analysis. When you can, make reasonable judgements about the likely size and direction of unquantified uncertainty. Provide a qualitative description informing users about why the uncertainty cannot be quantified and their likely impact.\n\n\n\n\nQ58\n\n\nIs workflow documentation including technical guides and code repositories publicly available?\n\n\nTransparency about your analysis supports proper scrutiny and challenge, promotes public trust, and encourages re-use of the resources you develop.\n\n\n\n\nQ59\n\n\nDoes the technical guide and documentation explain how to run the analysis to obtain valid outputs?\n\n\nA good technical guide helps everybody to understand what the analysis does and how it works. A well-written technical guide is essential for effective maintenance of the analysis. It helps users of the analysis to replicate the findings, get answers to methodology questions and build their trust in the output.\n\n\n\n\nQ60\n\n\nHave you fully documented the analysis code to comply with good practice?\n\n\nThe technical guide is complemented by fully documented analysis code. Code documentation must comply with good practice so new users can understand and execute the code as easily and quickly as possible.\n\n\n\n\nQ61\n\n\nAre users able to feed back on the suitability of outputs?\n\n\nExternal critique makes analysis more robust. Users should be able to give feedback to your team to ensure that results meet their needs. User feedback and customer reviews inform you of issues and changes that you might need to make. They also act as evidence that users have been consulted.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\nWhich Code practice(s) are most relevant here?\n*Trustworthiness (T), Quality (Q), Value (V)\n\n\n\n\nQ53\n\n\nCan you give a clear account of what can and cannot be inferred from the analysis?\n\n\nQ7.3 Explain the nature of data sources and why they were selected, anticipating possible areas of misunderstanding or misuse. Prominently communicate limitations in the underlying data and explain their impact on the statistics\n\n\n\n\nQ54\n\n\nHave you assessed the limitations of the data and analysis and set out how they affect the quality and use of the outputs?\n\n\nQ6.1 Regularly review strengths and limitations in the data and statistics, including the continued suitability of data sources and methods. Be open about your decisions and reasons for changeQ6.2 Use the most suitable data for what needs to be measured. Monitor for changes in the data sources and potential bias in the data. Explain any issues and their implications for use of the data in producing statisticsQ7.1 Prominently communicate the quality of the statistics and the strengths and limitations that impact their use, reflecting the needs of different types of users\n\n\n\n\nQ55\n\n\nHave you sense checked outputs with user groups and stakeholders?\n\n\nV8.3 Gain views from a range of users to inform decisions on your work programme, including when statistics are started, stopped or changed, being clear on where and why user needs can and cannot be met, such as addressing information gaps. Involve users in the ongoing development and testing of statistics\n\n\n\n\nQ56\n\n\nIs uncertainty about data quality, assumptions and methodology clearly communicated to users?\n\n\nQ7.2 Report on the key quality dimensions, such as accuracy and timeliness, and, where possible, give estimates of error and confidence for the statistics. Summarise how uncertainty in the estimates may impact use by using qualifying words, numbers or graphicsQ7.4 Be clear about the methods used. Explain quality issues related to the methods, systems and processes, including the extent to which the statistics are representative and comparable across the UK and internationally. Describe potential bias and steps taken to address it\n\n\n\n\nQ57\n\n\nAre the implications of unquantified uncertainties communicated to users?\n\n\nQ7.2 Report on the key quality dimensions, such as accuracy and timeliness, and, where possible, give estimates of error and confidence for the statistics. Summarise how uncertainty in the estimates may impact use by using qualifying words, numbers or graphicsV9.2 Communicate the statistics in a way that helps users understand issues and support them to make appropriately informed decisions. Provide a clear description of the main messages with suitable data visualisations\n\n\n\n\nQ58\n\n\nIs workflow documentation including technical guides and code repositories publicly available?\n\n\nV10.2 Make sure statistics, data and related guidance are easily accessible. Provide other relevant information, such as metadata and coding where appropriate\n\n\n\n\nQ59\n\n\nDoes the technical guide and documentation explain how to run the analysis to obtain valid outputs?\n\n\nV10.2 Make sure statistics, data and related guidance are easily accessible. Provide other relevant information, such as metadata and coding where appropriateV10.5 Support the reuse of data and statistics, preventing barriers to use where possible. Ensure statistics are reproducible. Support data and statistics to be shared, accessed and linked, using common data standards with associated metadata\n\n\n\n\nQ60\n\n\nHave you fully documented the analysis code to comply with good practice?\n\n\nQ6.7 Base methods on national or international good practice, scientific principles or professional consensus. Identify potential bias and address limitations. Use recognised standards, classifications and definitions. Explain reasons for deviations from these standards and any related implications for useV10.2 Make sure statistics, data and related guidance are easily accessible. Provide other relevant information, such as metadata and coding where appropriate\n\n\n\n\nQ61\n\n\nIs there a clear feedback mechanism so users can report back on the suitability of outputs?\n\n\nV8.1 Be accountable to users by providing the means for users to engage meaningfully in open and constructive ways, enabling questions to be asked and providing prompt responsesV8.3 Gain views from a range of users to inform decisions on your work programme, including when statistics are started, stopped or changed, being clear on where and why user needs can and cannot be met, such as addressing information gaps. Involve users in the ongoing development and testing of statistics\n\n\n\n\n\n\n\n\n\n\nQuality Question\n\n\nWhich AQuA role(s) would normally answer this?\n\n\nWhy are these AQuA roles involved?\n\n\n\n\nQ53\n\n\nCan you give a clear account of what can and cannot be inferred from the analysis?\n\n\nCommissioner, analyst\n\n\nDuring the delivery phase, the commissioner receives the results of the analysis and decides whether it meets their needs. The analyst provides sufficient information to support the commissioner to make an informed decision.\n\n\n\n\nQ54\n\n\nHave you assessed the limitations of the data and analysis and set out how they affect the quality and use of the outputs?\n\n\nCommissioner, Assurer, Analyst\n\n\nThe commissioner must be confident in the quality of the outputs. They should understand the strengths, limitations and context of the analysis so that the results are correctly interpreted. Assurer sign-off provides confidence that analysis risks, limitations and major assumptions are understood by the users of the analysis. Analysts make sure that the commissioner and assurer have the evidence they need.\n\n\n\n\nQ55\n\n\nHave you sense checked outputs with user groups and stakeholders?\n\n\nAnalyst, Assurer\n\n\nThe analyst and assurer should enable and encourage peer review. Peer reviews provide useful critical challenge about the analytical approach, application of methods and interpretation of the analysis. Verification and peer review of work should be done by analysts who had no involvemen in the work  so their views are independent.\n\n\n\n\nQ56\n\n\nIs uncertainty about data quality, assumptions and methodology clearly communicated to users?\n\n\nAnalyst, commissioner\n\n\nThe analyst must determine and communicate the uncertainty associated with the analysis so the commissioner can make informed decisions. The commissioner should ensure that an assessment of uncertainty has been provided and that the implications of uncertainty are understood.\n\n\n\n\nQ57\n\n\nAre the implications of unquantified uncertainties communicated to users?\n\n\nAnalyst, commissioner\n\n\nIf uncertainty is too complex to quantify, even approximately, the analysts should explain this so the commissioner can take this into account. In communicating analysis results to decision-makers and stakeholders, the commissioner should be open about the existence of deep uncertainties whose impact cannot be assessed, and explain how they are managed in the analysis.\n\n\n\n\nQ58\n\n\nIs documentation including technical guides and code repositories publicly available?\n\n\nAnalyst, Assurer\n\n\nThe analyst must produce appropriate design documentation. Best practice includes maintaining a record of the analysis workflow in a technical report, including a concept of analysis, user requirements, design specification, functional specification, data dictionary, and test plan. Code should be properly documented.\n\n\n\n\nQ59\n\n\nDoes the technical guide and documentation explain how to run the analysis to obtain valid outputs?\n\n\nAnalyst, Assurer\n\n\nThe analyst must produce appropriate documentation. Best practice includes maintaining a record of the work that has been done in a technical report, including a full description of the analysis, user requirements, design specification, functional specification, data dictionary, and test plan. The assurer makes sure that the documentation is fit for purpose.\n\n\n\n\nQ60\n\n\nHave you fully documented the analysis code to comply with good practice?\n\n\nAnalyst, Assurer\n\n\nAnalysts should develop and maintain analysis code in line with best practice. Code must comply with relevant policies and standards.\n\n\n\n\nQ61\n\n\nIs there a clear feedback mechanism so users can report back on the suitability of outputs?\n\n\nAnalyst, Approver\n\n\nYou can assess the usefulness of the analysis by getting feedback from users, stakeholders and other experts. Quality analysis should be free of prejudice or bias. The SRO and analysts should check that the analysis follows the principles of RIGOUR (Repeatable, Independent, Grounded in reality, Objective, Uncertainty-managed, Robust)",
    "crumbs": [
      "ONS QUALITY QUESTIONS"
    ]
  },
  {
    "objectID": "how_to_use.html",
    "href": "how_to_use.html",
    "title": "How to use ONS Quality Questions",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.",
    "crumbs": [
      "How to use the ONS Quality Questions"
    ]
  },
  {
    "objectID": "how_to_use.html#structure-of-the-ons-quality-questions",
    "href": "how_to_use.html#structure-of-the-ons-quality-questions",
    "title": "How to use ONS Quality Questions",
    "section": "Structure of the ONS Quality Questions",
    "text": "Structure of the ONS Quality Questions\nThere are 61 quality questions in total. They cover all the stages of the analytical cycle.\nAnswering 61 questions must seem quite daunting at first! The questions are designed to help you as you work your way through the analytical process, rather than to be answered all at once. Creating a log of answers as you move through the stages of the analysis workflow will help you to check that your work meets analytical standards, follows good practice and (if relevant) complies with the Code of Practice for Statistics.\nAnswering the questions will also help you make sure that everybody working on the analysis has a clear understanding of how and why it works as it does, and to support your users when writing your outputs. Moreover, most of the answers will help you to produce the critical documents that mitigate risk like an assumptions log, decisions log, issues log, and technical guides for your team and your users.\nThe AQuA book divides the analytical cycle into four stages:\n\nScoping\n\nDesign\n\nConducting and checking analysis\n\nDelivery\n\nYou can find the questions in the ONS Quality Questions section of the website. The questions have tabs which relate to three themes:\n\n\nTheme1: ONS Quality Questions and why they matter\n\nAlongside each question we explain why it matters and explain the potential risks and benefits around it. We try to address the very sensible question of “why should I care about this?”.\n\n\n\nTheme 2: The questions and the Code of Practice for Statistics\n\nEach question is linked with the Code of Practice for Statistics pillars of Trustworthiness, Quality and Value. We explain the importance and relevance of each question in light of the three pillars so teams can better understand and apply these principles through out the project life cycle.\nEven if your work does not directly feed into the production of official statistics, compliance with the principles and practices of the Code is a good way to strengthen the resilience of your work, increase transparency and clarity and reduce risk.\n\n\n\nTheme 3: Linking the questions to AQuA roles\n\nQuality questions are also linked to which responsible role from the AQuA book would usually answer them. The idea is to highlight the clear line of accountability set out in the AQuA book in an easy-to-understand manner. We want to make it easier for teams to decide how the four key assurance roles of Commissioner, Approver, Analyst and Assurer are covered in their own workflows.\nThe AQuA book sets out four roles that cover different areas of assurance responsibility. Taken together, they provide a comprehensive set of assurance for an analytical project. The roles are:\n\nCommissioner (may be known as customer)\n\nAnalyst\n\nAssurer (may be known as the analytical assurer or assuring analyst)\nApprover (may be known as senior analyst or senior responsible officer)\n\nLet’s look at the roles more detail.\nResponsibilities of the Commissioner\nThe commissioner is focused on making sure the analysis meets the required user needs.\nEnsures that the context around the work is understood, so quality assurance is appropriate and proportionate. Ensures that there is enough time and resource for required assurance, and accounts for risk. Must understand strengths and limitations including uncertainty, so results are interpreted correctly. Delivers QUALITY OF OUTCOME — “The analysis meets user needs and we understand its limitations.” Requests the analysis and sets out their requirements. Agrees that what the analyst is going to do will satisfy the need. Accepts the analysis and assurance as fit for purpose.\nResponsibilities of the Approver\nThe Approver is accountable for the analytical workflow throughout its lifecycle. Usually a senior member of the analytical team, they work closely with (or manage) the analyst team.\nSigns off all important decisions made about the analysis to ensure that it is fit-for-purpose prior to use. Scrutinises the work of the analyst and the assurer. Confirms (if necessary) to the analyst, assurer, and commissioner that the work has been appropriately assured. There is no minimum grade for the SRO role, but they should have the expertise, resources and accountability to ensure that the analysis is well-designed, complies with relevant standards, works as intended and is fit for purpose. Delivers QUALITY OF CONTENT — “The analysis is well-designed and uses the right tools and methods to meet user needs.” — alongside the analyst team.\nResponsibilities of the Analyst\nThe analyst team usually works to the SRO. Analysts are responsible for setting up, running, checking and reporting on the analysis.\nAssist the Commissioner and SRO in framing the question to ensure the right analysis is done. Manage external specialists. Design, build, document, and run analyses. Carries out their own assurance. Acts on findings from the assurer. Can be a group of analysts, in which case the lead analyst is responsible. Delivers QUALITY OF CONTENT — “The analysis is well-designed and uses the right tools and methods to meet user needs.” — alongside the SRO.\nResponsibilities of the Assurer\nThe assurer is there to make sure high-level assurance takes place.\nAssurance takes place throughout the lifecycle — from design through to use. Reviews the assurance completed by the analyst. Carries out any further validation and verification they may see as appropriate. Reports errors and areas for improvement to the analyst. Undertakes repeated reviews as required. Confirms to the approver that the work has been appropriately scoped, executed, validated, verified, and documented. Must be independent from the analyst. Can be a group of assurers, in which case the leader of the group is responsible. Delivers QUALITY OF PROCESS — “The analysis does what it’s supposed to do — and we can prove it.”\nYou can read more about the four roles in the AQuA Book and Verification and Validation for the AQuA Book.",
    "crumbs": [
      "How to use the ONS Quality Questions"
    ]
  },
  {
    "objectID": "how_to_use.html#answering-the-ons-quality-questions",
    "href": "how_to_use.html#answering-the-ons-quality-questions",
    "title": "How to use ONS Quality Questions",
    "section": "Answering the ONS Quality Questions",
    "text": "Answering the ONS Quality Questions\nWe have made templates for you to download and use to record your answers to the questions, as well as key project information. There is an Excel template and an editable HTML template.\nSave the template in your project repository or on Sharepoint so that changes can be tracked through version control. You can update it as your analytical work progresses.\nWe encourage the commissioner, analyst team and assurer to contribute response to all the questions that are relevant to their responsibilities. To keep the level of assurance proportionate to your analysis it might be decided that only a subset of questions need be covered.\n\n\n\n\n\n\nNoteIs there any help in deciding which questions should be covered?\n\n\n\n\n\nThe commissioner and lead analyst should agree the level of assurance required and identify which questions are most appropriate together with any possible additional ones.\nThe Excel template has mapped the questions to various categories including Analysis Function’s Quality Questions and Red Flags and the OSR’s Statistical Thinking – both these publications promote their questions as a core set that anyone doing analysis should consider. To identify these questions it is only necessary to filter on the appropriate columns in the worksheet.\nIt is also possible to filter questions relevant for each stage of the Generic Statistical Business Process Model. Many questions are relevant for more than GSBPM stage and only need be answered once!\nWe aim to add further categories to subset questions best suitable for production, research and adhoc projects. These would only be suggestive but could provide a start.\n\n\n\nFor audit purposes, remember to sign and date your responses.\nWhen analysis is due to complete the lead analyst or their designated representative should provide sign-off for the whole template if satisfied that responses provide sufficient assurance of the analysis.",
    "crumbs": [
      "How to use the ONS Quality Questions"
    ]
  },
  {
    "objectID": "faqs.html",
    "href": "faqs.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.",
    "crumbs": [
      "Support and Feedback",
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#when-should-i-use-this-guidance",
    "href": "faqs.html#when-should-i-use-this-guidance",
    "title": "Frequently Asked Questions",
    "section": "When should I use this guidance?",
    "text": "When should I use this guidance?\nIf you are starting work on a new analysis project we recommend that you use this guidance right from the scoping stage. For teams who are in the middle of an analysis, you can still use the guidance and templates to think about the quality questions from the scoping and design stages and continue recording the answers up until the delivery stage.",
    "crumbs": [
      "Support and Feedback",
      "FAQs"
    ]
  },
  {
    "objectID": "faqs.html#which-analysis-is-in-scope-of-the-guidance",
    "href": "faqs.html#which-analysis-is-in-scope-of-the-guidance",
    "title": "Frequently Asked Questions",
    "section": "Which analysis is in scope of the guidance?",
    "text": "Which analysis is in scope of the guidance?\nThe guidance applies to all analysis workflows, including:\n\nanalysis to support research,\nadvice for other departments,\nad-hoc and one-off outputs\nand regular outputs.\n\n\n\n\n\n\n\nNoteRegular outputs as business critical models\n\n\n\n\n\nRegular outputs often fulfil at least one of the criteria for what makes a business critical model:\n\nUnderpins essential financial and funding decisions;\n\nEssential to the achievement of business plan actions and priorities;\n\nMust be error free or else risk serious financial or legal penalties or reputational damage for the organisation.\n\nBusiness critical analysis requires the highest level of scrutiny and the governance arrangements must be appropriate for the level of risk.\n\n\n\n\n\n\n\n\n\nNoteHow should the questions be used for ad-hoc analysis?\n\n\n\n\n\nFor ad-hoc outputs with quick turnarounds and limited time and resources, analysis still needs sufficient quality assurance to ensure it is fit for purpose. Ad-hoc outputs are often used as part of the evidence when making important policy decisions, so getting them right is very important.\nWe strongly encourage approvers of both regular and ad-hoc analysis to answer all questions relevant to their role.\n\n\n\n\n\n\n\n\n\nNoteWhy should these questions and assurance logs be completed?\n\n\n\n\n\nCompleting the logs makes it much easier to understand the risks that the analysis carries and will help you plan to mitigate them. Having a proper audit trail and comprehensive logs also help when:\n\nYou need to explain why the analysis works as it does.\n\nYou need to raise quality and resourcing issues and push back against demands that are unrealistic.\n\nYou need to understand and communicate potential risks.\n\n\n\n\n\n\n\n\n\n\n\nNoteHow should I identify the Approver, Commissioner, Analyst and Assurer?\n\n\n\n\n\nThe AQuA Book sets out four roles responsible for the assurance of analysis:\n\nCommissioner\n\nAnalyst (who usually report to the approver)\n\nAssurer\n\nApprover (usually leads the analyst team)\n\nWhat matters here is that each assurance role is covered in your workflow and that individuals know about and accept their responsibilities, not the name of the role.\nAs a project team, you should make sure that each role is in place and you understand how it will operate for you so that you have the right assurance.\nThe AQuA Book makes no expectations about levels of seniority or grade of each of the occupiers of the roles. It does not specify whether roles should be held by a person or could be held by a committee or other governance group (such as a senior leadership team).\nThe key consideration is whether or not the person or group that undertakes the assurance role have the skills and resources they need to meet the requirements of the role. How the roles are covered in an analysis workflow varies from project to project, depending on how the work is planned, managed and assured.\nWe suggest that if roles are taken by individuals, the SRO and commissioner should usually be at Grade 7 or above. If you are still unsure about how to allocate the roles among your team and governance groups, please email us with “analysis assurance” in the subject header and we will help you to make the decision.\n\n\n\n\n\n\n\n\n\nNoteWhat help is available to answer the quality questions?\n\n\n\n\n\nFor ONS staff, the ONS Quality Central wiki contains lots of useful guidance, templates and mandatory training to help you work through and answer the quality questions. It includes the ONS Quality Standard for Analysis.\nThese cross-government resources are also likely to be useful:\n* Government Data Quality Hub Quality Questions and Red Flags and Government Data Quality Framework\n* Office for Statistics Regulation Quality Assurance of Administrative Data toolkit and Quality and statistics: an OSR perspective.\n* The Uncertainty Toolkit for Analysts in Government\n\n\n\n\n\n\n\n\n\nNoteWhat are Black Box Models in AI, and why do they matter for quality assurance?\n\n\n\n\n\nBlack box models are AI systems whose internal workings are not easily understood or explained, even by their developers. These models—often based on complex algorithms like deep learning—can produce highly accurate results, but their decision-making processes are opaque.\nWhy is this a quality concern? * Lack of transparency makes it difficult to verify how decisions are made. * Hard to audit for fairness, bias, or compliance with regulations. * Reduced trust from users and stakeholders who need clarity and accountability.\nHow does AI assurance help?\nAI assurance provides tools and processes to evaluate and communicate the trustworthiness of black box models. This includes:\n\nExplainability techniques to make outputs more understandable.\nAudits and impact assessments to check for ethical and legal risks.\nTesting and validation to ensure consistent and fair performance.\n\nWhat should I look for when reviewing black box models?\n\nIs there a clear explanation of how the model works or why it made a decision?\nHas the model been tested for bias, fairness, and robustness?\nAre there documented assurance activities (e.g., audits, assessments)?\nIs the model aligned with principles like transparency, accountability, and safety?\n\nYou can find more guidance on AI assurance here. (https://www.gov.uk/government/publications/introduction-to-ai-assurance/introduction-to-ai-assurance)",
    "crumbs": [
      "Support and Feedback",
      "FAQs"
    ]
  },
  {
    "objectID": "assumptions_and_issues_log.html",
    "href": "assumptions_and_issues_log.html",
    "title": "Assumptions and decision log guide",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.\nAnalysis always involves assumptions and decisions. It always has limitations, which might mean that it is not fit for purpose for every use case.\nKeeping a formal record of assumptions, decisions and key limitations (such as the uncertainty involved in the analysis) and bringing them together in one place means that everybody involved in the work can find them quickly, see what they are and understand how they might affect the overall analysis or the part they are working on.\nThis really matters, because assumptions, decisions and limitations underpin fitness for purpose. They also change. They might become obsolete, or be replaced or adapted as you understand more. A log that brings all this together in one place will really help you to manage your analysis openly and transparently across everybody who works on the analysis. It helps everybody to have a clear, shared understanding of what is being done and why. It also makes it much easier to audit and assure your work, explain it to others, and to provide assurance that the analysis is fit for purpose.\nWe have developed an assumptions and decisions log template for you to download. It provides the basis for recording your assumptions, decisions and limitations (identified as risks and issues). The template includes multiple worksheets to record full project information.\nDetails for recording information in each log is as follows.",
    "crumbs": [
      "Assumptions and decision log guide"
    ]
  },
  {
    "objectID": "assumptions_and_issues_log.html#field-definitions",
    "href": "assumptions_and_issues_log.html#field-definitions",
    "title": "Assumptions and decision log guide",
    "section": "Field definitions",
    "text": "Field definitions\n\n\n\n\n\n\n\nField\nDefinition\n\n\n\n\nAssumption ID:\nGive each assumption a unique ID so that it can be tracked easily and cross referenced.\n\n\nThis Assumption depends on other Assumptions:\nIdentify the IDs of dependencies\n\n\nLocation in code, documentation or publication:\nWrite the name of the document or publication where the assumption is applied. If the assumption is applied in your code, identify where the assumption applies by citing the module and line number.\n\n\nPlain English description of assumption:\nWrite a clear description of the assumption in plain English. For example, “We assume that our sample of income data is representative for the whole population”.\n\n\nBasis for assumption:\nBriefly summarise why the assumption matters for the analysis and why it is reasonable. For example, the assumption could be based on historical data, theoretical requirements of the method, empirical evidence, quality assurance, common practice or data testing.\n\n\nNumerical value of the assumption:\nIf you can, attach a numerical value to the assumption. This will depend on what the assumption is and how it is applied in your work. For example, you might make an assumption that counts in your data are accurate to within 5 units, so you would record +/- 5 as the numerical value. Thinking about the value of the assumption in numeric terms is a useful way to work through its impact on your work.\n\n\nRange around the estimated value:\nAssumptions are rarely certain. If you can, assign a range to the central value of the assumption.\n\n\nLinks to supporting analysis:\nAttach a link to where the assumption comes from or from where it can be verified and justified.\n\n\nDocumentation dependencies:\nList the project documents dealing with this assumption. Assumptions can have an impact on different stages of the analysis. For example, an assumption about input data if valid or invalid could impact the analysis code, project timeline and the robustness of the outputs produced by the analysis. Logging these dependencies will ensure that the relevant plans and documents are updated once an assumption is validated.\n\n\nInternally reviewed by:\nEnter the full name of individual or group who reviewed the assumption.\n\n\nDate of last review/update:\nEnter the date the assumption was last reviewed or validated.\n\n\nExternally reviewed by:\nEnter the name of organisation and the position of the expert who validated the assumption. It is not necessary to mention the individual’s name. For example, Lighthouse Laboratory (Senior Scientist), University of Oxford (Professor of Statistics).\n\n\nDate of external review:\nEnter the date the assumption was reviewed by the external expert.\n\n\nNext review/update due on:\nEnter the date the assumption next needs to be reviewed or updated.\n\n\nQuality Rating:\nUse the Quality Rating key (on the Quality and Sensitivity Guide worksheet) to assess quality of assumption as red, amber or green.\n\n\nSensitivity Score:\nUse the Sensitivity Rating key (on the Quality and Sensitivity Guide worksheet) to assess sensitivity as low, medium or high.\n\n\nRisk Score:\nUse the Risk Scoring Guide worksheet to assess the assumption risk as low, medium or high.",
    "crumbs": [
      "Assumptions and decision log guide"
    ]
  },
  {
    "objectID": "assumptions_and_issues_log.html#field-definitions-1",
    "href": "assumptions_and_issues_log.html#field-definitions-1",
    "title": "Assumptions and decision log guide",
    "section": "Field definitions",
    "text": "Field definitions\n\n\n\n\n\n\n\nField\nDefinition\n\n\n\n\nDecision ID:\nGive each decision a unique ID so that it can be tracked easily and cross referenced.\n\n\nDecision name:\nEnter a name for the decision.\n\n\nDate of decision:\nEnter the date the decision was made.\n\n\nPlain English description of decision\nA brief summary of the decision in plain English explaining what it was about and how it applies in the analysis.\n\n\nName of person or group signing off the decision:\nEnter the name of the person or group who made the decision. If the decision was made by a committee, link to the minute where the decision is documented.\n\n\nRole of person or group signing off the decision:\nProvide a short description of the person or group’s role in the project. Decisions are often signed off by the project lead or Senior Responsible Owner, for example.\n\n\nDate of last review / update:\nDate the decision was last considered. This is here so you know when the decision was last looked at. Projects evolve, and decisions might need to be reviewed.\n\n\nReviewed by:\nName(s) of people or group who last reviewed the decision.\n\n\nNext review/update due on:\nEnter the date the decision next needs to be reviewed or updated.",
    "crumbs": [
      "Assumptions and decision log guide"
    ]
  },
  {
    "objectID": "assumptions_and_issues_log.html#field-definitions-2",
    "href": "assumptions_and_issues_log.html#field-definitions-2",
    "title": "Assumptions and decision log guide",
    "section": "Field definitions",
    "text": "Field definitions\n\n\n\n\n\n\n\nField\nDefinition\n\n\n\n\nIssue ID:\nGive each issue a unique ID so that it can be tracked easily and cross referenced.\n\n\nIssue name:\nEnter a name for the issue. It could be anything raised by the team, anything raised during quality assurance by the team members or external reviewers. Include the location of the issue, for example, line number of code, error in publication, where it arises in the workflow, resource constraint.\n\n\nDate identified:\nEnter the date the issue was first identified.\n\n\nPlain English description of issue:\nA brief summary of the underlying cause and nature of issue in plain English explaining what is creating problem.\n\n\nImpact of issue:\nBrief summary of how the issue affects the project, for example, timeline, accuracy, cost.\n\n\nStatus of issue:\nFrom the dropdown menu, select ‘Live’ if the issue is being handled, ‘Resolved’ if the issue has been resolved or ‘Untreated’ if the issue has yet to be handled.\n\n\nJustification of status:\nBrief summary of how the solution has resolved the issue if the status is ‘Resolved’. For ‘Untreated’ issues, explain why the issue will be dealt with later.\n\n\nProof of resolution:\nWrite the name of the output report/methodology paper or the published document where the issue is resolved. If the issue relates to code, identify the module and line number.\n\n\nDate of last review/update:\nEnter the date the issue was last reviewed or updated.\n\n\nReviewed by:\nEnter the full name of individual(s) or group who reviewed the issue.\n\n\nNext review/update due on:\nEnter the date the issue next needs to be reviewed or updated.",
    "crumbs": [
      "Assumptions and decision log guide"
    ]
  },
  {
    "objectID": "feedback.html",
    "href": "feedback.html",
    "title": "Feedback",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.\n\n\n\n\nFeedback\nWe are keen to understand the challenges faced by analytical teams in ONS when complying with good practice. To evaluate the effectiveness of this guidance, we would be grateful if you could fill in a short survey.\nWe appreciate your feedback. It will help us to make additional tools and resources on good practice for producing quality analysis.\nIf you have questions about this guidance or the survey please email ASAP@ons.gov.uk “analytical QA” in the subject header.",
    "crumbs": [
      "Support and Feedback",
      "Feedback"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ONS Quality Questions Introduction",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#who-is-this-guidance-for",
    "href": "index.html#who-is-this-guidance-for",
    "title": "ONS Quality Questions Introduction",
    "section": "Who is this guidance for?",
    "text": "Who is this guidance for?\nThis guidance provides a set of questions to help analytical and statistical teams evaluate the quality of their analysis throughout the production cycle.\nThe guidance is here to support teams in meeting the Office for National Statistics’s (ONS) strategic objectives for improving statistical quality. You can find more information about our strategic objectives on statistical quality in the ONS Statistical Quality Improvement Strategy. ONS manages quality through a strategic risk approach.\nWe have made the guidance available on Github in case others wish to use the Quality Questions resource in their own work.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#aims",
    "href": "index.html#aims",
    "title": "ONS Quality Questions Introduction",
    "section": "Aims",
    "text": "Aims\nThe guidance has five main aims:\n\nTo help analysts understand the level of risk they are carrying in their analytical workflows.\nTo ensure there is a consistent end-to-end QA approach across ONS.\n\nTo make it easier to comply with good practice guidance and standards including the ONS Quality Practices, ONS Quality Standard for Analysis, the government AQUA Book and the Code of Practice for Statistics, the Analysis Function Functional Standard for Analysis and the Government Service Manual which explains how to research, document and validate user needs.\n\nTo ensure there is a consistent understanding of roles and responsibilities when producing high quality analysis and statistics.\n\nTo make it easier to create critical project documentation including an assumptions and decisions log, issue and decisions log, risk register and divisional Quality Improvement Plan.\n\nReflecting on the questions asked in the template will help you to manage your analysis risks:\n\nYou will be able to document the mitigation that is in place or planned.\n\nYou will know which issues and risks the project is prepared to accept and why.\n\nYou can identify potential quality issues and decide how to manage and prioritise them.\n\nHaving this information in once place provides a sound basis for regular reviews of assumptions, issues and risks associated with the workflow, in line with recommended good practice.\n\n\n\n\n\n\n\nNoteHow the questions draw on other frameworks\n\n\n\n\n\nThe AQuA book sets out a standard framework for managing analytical quality in HM Government. AQuA is there to make sure that our work can be trusted to inform good decision making, while the Code of Practice for Statistics sets out the principles and practices that producers of official statistics should commit to.\nTwo other pieces of guidance have motivated us to produce this template. One is the Analysis Function guidance on Quality Questions and Red Flags. The other is the Office for Statistics Regulation (OSR) guidance on Thinking about quality when producing statistics. Both of these provide sets of questions that analysts can use to interrogate their work and assure its quality.\nBuilding on these resources, this guidance sets out quality questions that are relevant for each stage of analytical cycle. The quality questions are at their most effective if they are asked at the right stage. Once that stage is passed, experience suggests that it is normally difficult to go back and address the points the questions ask by retrofitting at a later stage of the analysis.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "quality_questions_markdown_version.html",
    "href": "quality_questions_markdown_version.html",
    "title": "Quality Questions",
    "section": "",
    "text": "Note\n\n\n\n\n\nThis guidance is an ALPHA draft. It is in development and we are still working to ensure that it meets user needs.\nPlease get in touch with feedback to support the guidance by creating a GitHub Issue or emailing us.\nTo make the most out of this template, we strongly recommend that you identify who will take the three key quality assurance roles of Commissioner, Senior Responsible Owner and Analytical Assurer at the start of the analytical cycle. This is crucial as each of these individuals has a role in ensuring that the analysis you do is fit-for-purpose. You should also identify the members of the analytical team. If team members have specific roles, record them here and update them when they change."
  },
  {
    "objectID": "quality_questions_markdown_version.html#lead-analytical-roles",
    "href": "quality_questions_markdown_version.html#lead-analytical-roles",
    "title": "Quality Questions",
    "section": "Lead analytical roles",
    "text": "Lead analytical roles\n\n\n\n\n\n\n\n\n\nName of Senior Responsible Owner (SRO)\nName of Commissioner\nName of Analyst(s)\nName of Analytical Assurer(s)\n\n\n\n\nEnter name here\nEnter name here\nEnter name here\nEnter name here"
  },
  {
    "objectID": "quality_questions_markdown_version.html#quality-questions",
    "href": "quality_questions_markdown_version.html#quality-questions",
    "title": "Quality Questions",
    "section": "Quality Questions",
    "text": "Quality Questions\n\n\n\n\n\n\n\n\n\n\n\n\n\nScoping\nQuality question\nAnswer\nAnswer added by\nDate of answer\nAnswer signed off by SRO?\nNext review due date\nChanges since last review\n\n\n\n\nQ1\nWhat question is the analysis trying to answer?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ2\nWhy do you need to answer this analysis question?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ3\nWhich organisational priorities does this analysis address?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ4\nIf you use a model, is it business critical?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ5\nWho needs the answer to the analysis question?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ6\nWho do you need to consult to make sure you meet the right user needs?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\n\n\n\nQ7\nHow will you know you have answered the analysis question correctly?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\n\n\n\nQ8\nWhat is the estimated time and resource required to answer the analysis question (in months and FTE)?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ9\nWhat is the impact if the analysis is not done now?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ10\nWhat is the impact if the work is not done correctly?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ11\nName the commissioner, senior responsible owner and analytical assurer of this analysis?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ12\nWhat tools and resources will you use in production? Are they the best for the job?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ13\nDo you have the right internal and external resources and capability to deliver the analysis?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ14\nWhat are the anticipated risks of the analysis? Have you discussed these risks with customers and stakeholders?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ15\nIs there a contingency plan prepared if your mitigation plans fail?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ16\nDo the data and analysis comply with ethical requirements?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ17\nWhat relevant questions are outside the scope of the analysis?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ18\nHow will you peer review and assure the work?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ19\nWill external experts be involved in development and scrutiny of analysis?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign\nQuality question\nAnswer\nAnswer added by\nDate of answer\nAnswer signed off by SRO?\nNext review due date\nChanges since last review\n\n\n\n\nQ20\nIs there a simple description in plain English of what the analysis is for and what it does?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ21\nDoes the analysis have a logic flowchart which explains the end-to-end conceptual steps in the work flow?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ22\nWhen do you expect to start and finish each stage of analysis i.e., data collection, processing, quality assuarnce, analaysis and dissemination?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ23\nDoes any part of the analysis rely on manual processing? Have you considered the cost and benefits of fully automating the process?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ24\nWhat happens if any of your team members, reviewers or users find a mistake in your analysis? Do you have a clear and efficient process for addressing the concern and preventing it from happening again?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ25\nHave you assessed uncertainty?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoing and checking the analysis\nQuality question\nAnswer\nAnswer added by\nDate of answer\nAnswer signed off by SRO?\nNext review due date\nChanges since last review\n\n\n\n\nQ26\nHow the data used in the analysis will be processed prior to and during use?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ27\nIs the data appropriate given the methods selected?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ28\nWhat are the strengths and limitations of the data that you use?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ29\nIs there a robust relationship between your team and data providers? Does your data provider have a good understanding of how and why you are using their data? Do you have a good understanding of how the data provider collects, processes and quality assures the data?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ30\nIs there a formal agreement in place that specifies when, what and how the data will be received? If not, would this be helpful?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ31\nDo you know what quality checks are carried out on the data before you receive them?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ32\nHow will you work with your data provider when your data requirements change?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ33\nHow do you know if your data provider makes a change to their systems or processes, which could impact the data you receive and/or the statistics you produce?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ34\nHow did you choose the methods for the analysis? How do you know the method you are using is appropriate?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ35\nHave reasonable alternative methods been explored and rejected for good reasons?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ36\nHow do you know that your analysis works correctly?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ37\nCan you describe the assumptions of your analysis, when they were made and who made them and signed them off?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ38\nHow are your assumptions validated and assured prior to use?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ39\nHow do you measure and report uncertainty in your analysis?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ40\nHave you thought about the implications of any unquantified uncertainties?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ41\nCan you explain how your analysis feeds into downstream processes? Are there any risks around these dependencies?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ42\nIs all or part of the analysis reliant on a single person? If yes, how are you mitigating this risk?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ43\nIs it clear why important decisions were made and who made them?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ44\nIf changes are made to code or datasets, can you easily track who made the changes and why the changes were made?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ45\nCould another analyst carry out the analysis and make the outputs just by reading documentation and desk instructions without needing to consult with anybody else?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ46\nDo you use peer review to check scripts and code, documentation, implementation of methods, processes and outputs?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ47\nIs your code and analysis ever peer reviewed by someone outside your team or organisation?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ48\nWhat is your assessment of the quality of your analytical outputs?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ49\nHow do you assure yourselves that analysis carried out is correct?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ50\nDo the outputs of your analysis match reported content?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ51\nIf you find outliers or unusual trends in the data, what steps are taken to investigate them?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDelivery\nQuality question\nAnswer\nAnswer added by\nDate of answer\nAnswer signed off by SRO?\nNext review due date\nChanges since last review\n\n\n\n\nQ52\nCan you give a clear account of what can and cannot be inferred from your final output? Q52 Could you give a clear account of what can and cannot be inferred from your final output?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ53\nHave you assessed the impact of the data and analysis limitations and set out how they will affect the quality and use of the outputs?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ54\nHave you sense checked outputs with user groups and stakeholders?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ55\nIs uncertainty about data quality, assumptions and methodology clearly communicated to users?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ56\nAre the implications of unquantified uncertainties communicated to users?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ57\nIs analysis documentation, including technical guides and code, publicly available?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ58\nDoes the technical guide explain how to use the analysis to obtain valid outputs?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ59\nHave you fully documented the analysis code?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text\n\n\nQ60\nAre users able to feed back on the suitability of outputs?\nEnter your answer here…\nEnter name\nEnter date\nYes/No\nEnter next review date\nEnter text"
  }
]